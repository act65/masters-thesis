{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as rnd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "import sklearn.cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutations(elems, T):\n",
    "    def recurse(xs):\n",
    "        if len(xs[0]) >= T:\n",
    "            return xs\n",
    "        else:\n",
    "            return recurse([x+[e] for x in xs for e in elems]) # + xs\n",
    "            \n",
    "    return recurse([[e] for e in elems])\n",
    "\n",
    "class RndOptionPolicy():\n",
    "    def __init__(self, n_actions, n_time_steps):\n",
    "        self.options = np.array(permutations(range(n_actions), n_time_steps))\n",
    "        \n",
    "    def __call__(self, x):\n",
    "        rnd_idx = rnd.choice(np.arange(self.options.shape[0]))\n",
    "        return self.options[rnd_idx]\n",
    "     \n",
    "class OptionEnvWrapper():\n",
    "    def __init__(self, env):\n",
    "        self.env = env\n",
    "        \n",
    "    def step(self, s, actions):\n",
    "        R = 0\n",
    "        for a in actions:\n",
    "            s, r = self.env.step(s, a)\n",
    "            R += r\n",
    "        return s, R\n",
    "\n",
    "    def reset(self):\n",
    "        return self.env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils\n",
    "def onehot(idx, N): # hacky. i know...\n",
    "    return np.eye(N)[idx]\n",
    "\n",
    "def softmax(x):\n",
    "    return np.exp(x)/np.sum(np.exp(x))\n",
    "\n",
    "class Env():\n",
    "    def __init__(self, n_states, n_actions):\n",
    "        self.n_states = n_states\n",
    "        self.S = np.arange(n_states)\n",
    "        self.A = np.arange(n_actions)\n",
    "\n",
    "        # model the transitions as linear fns conditional on the action.\n",
    "        # P = np.random.standard_normal([n_actions, n_states, n_states]) **2 # make sharper\n",
    "\n",
    "        # deterministic transition fn\n",
    "        # each action move from state(i) to state(j) with probability 1.\n",
    "        # BUG nope. softmax doesnt do this. will need to set to -infty\n",
    "        self.P = 20*np.stack([np.random.permutation(np.eye(n_states, dtype=np.float32)) for _ in range(n_actions-1)] + [np.eye(n_states, dtype=np.float32)],axis=0)  \n",
    "        # TODO what if there is structure in P? Low rank? Shared over actions?\n",
    "        # QUESTION how does this parameterisation effect things?\n",
    "        # NOTE this graph might be disconnected. but is unlikely!?\n",
    "\n",
    "        # reward is only a fn of the current state - shape = [n_states]\n",
    "        # also. is sparse.\n",
    "        self.R = onehot(np.random.randint(0, n_states), n_states)\n",
    "\n",
    "    def step(self, state, action):\n",
    "        \"\"\"\n",
    "        A tabular, probabilistic step function. \n",
    "\n",
    "        Args:\n",
    "            state (int): An element of S. The current state\n",
    "            state (int): An element of A. The action to be taken\n",
    "\n",
    "        Returns:\n",
    "            new_state (int): An element of S.\n",
    "        \"\"\"\n",
    "        # step by selecting relevant transition matrix and applying\n",
    "        logits = np.matmul(self.P[action, ...], onehot(state, self.n_states))\n",
    "        # convert to a distribution and sample\n",
    "        new_s = np.random.choice(self.S, p=softmax(logits))\n",
    "        return new_s, self.R[new_s]\n",
    "    \n",
    "    def rnd_policy(self, s, *args):\n",
    "        return np.random.choice(self.A)\n",
    "    \n",
    "    def reset(self):\n",
    "        return np.random.choice(self.S)\n",
    "\n",
    "    def new_task(self):\n",
    "        self.R = onehot(np.random.randint(0, self.n_states), self.n_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4096, array([2, 3, 0, 1, 0, 3]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_actions = 4\n",
    "n_states = 24\n",
    "env = Env(n_states, n_actions)\n",
    "rnd_policy = lambda obs: env.action_space.sample()\n",
    "op = RndOptionPolicy(n_actions, 6)\n",
    "env = OptionEnvWrapper(env)\n",
    "len(op.options), op(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_episode(env, player, T=5):\n",
    "    # reset\n",
    "    s = env.reset()\n",
    "    R = 0\n",
    "    done = False\n",
    "    pairs = []\n",
    "    \n",
    "    # play an episode\n",
    "    for _ in range(10):\n",
    "\n",
    "        a = player(s)\n",
    "        new_s, r = env.step(s, a)\n",
    "        R += r\n",
    "        \n",
    "        pairs.append((np.concatenate([onehot(new_s, n_states), np.array([0])]), \n",
    "                      a, \n",
    "                      np.concatenate([onehot(new_s, n_states), np.array([R])])))\n",
    "        s = new_s\n",
    "            \n",
    "    return pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       "  array([0, 0, 2, 2, 3, 3]),\n",
       "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       " (array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       "  array([1, 2, 2, 1, 1, 1]),\n",
       "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 0., 0.])),\n",
       " (array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       "  array([1, 1, 0, 2, 0, 1]),\n",
       "  array([0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       " (array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       "  array([3, 3, 1, 3, 0, 0]),\n",
       "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 0., 0., 0.])),\n",
       " (array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 0., 0.]),\n",
       "  array([3, 2, 1, 1, 3, 1]),\n",
       "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 0., 0.])),\n",
       " (array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 1., 0.]),\n",
       "  array([3, 1, 2, 2, 3, 2]),\n",
       "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 1., 0.])),\n",
       " (array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       "  array([3, 1, 2, 1, 2, 1]),\n",
       "  array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       " (array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       "  array([2, 3, 1, 2, 0, 3]),\n",
       "  array([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.])),\n",
       " (array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       "  array([3, 0, 0, 0, 2, 2]),\n",
       "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         1., 0., 0., 0., 0., 0., 0., 0.])),\n",
       " (array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       "  array([3, 1, 2, 3, 2, 0]),\n",
       "  array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0.]))]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "play_episode(env, op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pairs():\n",
    "    pairs = play_episode(env,op)\n",
    "    pairs = tuple(zip(*pairs))\n",
    "    return tuple([np.vstack(p) for p in pairs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n(n):\n",
    "    pairs = [get_pairs() for i in range(n)]\n",
    "    pairs = tuple(zip(*pairs))\n",
    "    return tuple([np.vstack(p) for p in pairs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((30, 25), (30, 6), (30, 25))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_n(3)[0].shape, get_n(3)[1].shape, get_n(3)[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = sklearn.cluster.MiniBatchKMeans(n_clusters=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(200):\n",
    "    states = []\n",
    "    s, p, st = get_n(50)\n",
    "    kmeans.partial_fit(st-s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 25)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.cluster_centers_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0.,   0.,   0.,   0.,   0., 500.,   0.,   0.,   0.,   0.]),\n",
       " array([-0.5, -0.4, -0.3, -0.2, -0.1,  0. ,  0.1,  0.2,  0.3,  0.4,  0.5]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(kmeans.predict(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
