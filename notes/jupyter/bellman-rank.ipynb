{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy.random as rnd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want to make some Bellman error matrices as defined [here](https://arxiv.org/abs/1610.09512)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_states = 2\n",
    "n_actions = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4, 2), (4, 1))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_rnd_problem(n_states, n_actions):\n",
    "    P = rnd.random((n_states * n_actions, n_states))**2\n",
    "    P = P/P.sum(axis=1, keepdims=True)\n",
    "    r = rnd.random((n_states * n_actions, 1))\n",
    "    return P, r\n",
    "\n",
    "P, r = generate_rnd_problem(n_states, n_actions)\n",
    "P.shape, r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def low_rank_approx(M, r=1):\n",
    "#     n, m = M.shape\n",
    "#     u, s, vT = np.linalg.svd(A, full_matrices=False)\n",
    "#     A = np.zeros((n, m))\n",
    "#     for i in range(r):\n",
    "#         A += s[i] * np.outer(u.T[i], v[i])\n",
    "#     return A\n",
    "\n",
    "# low_rank_approx()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.   0.25 0.5  0.75 1.  ]\n"
     ]
    }
   ],
   "source": [
    "vals = np.linspace(0.0, 1.0, 5)\n",
    "print(vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "625"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function class\n",
    "# $f \\in \\{X \\times A \\to [0, 1]\\}$\n",
    "fn_class = list(itertools.product(*[vals for _ in range(n_actions * n_states)]))\n",
    "len(fn_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_Mpi(n_states, n_actions, ps):\n",
    "    \"\"\"\n",
    "    A policy is represented by a block diagonal |S| x |S||A| matrix M.\n",
    "\n",
    "    Args:\n",
    "        n_states (int): the number of states\n",
    "        n-actions (int): the number of actions\n",
    "        ps (array[n_states, n_actions]): the probabilities of taking action a in state s.\n",
    "\n",
    "    Returns:\n",
    "        (array[n_states, n_states x n_actions])\n",
    "    \"\"\"\n",
    "    A = np.ones((1, n_actions))\n",
    "    S = np.eye(n_states)\n",
    "\n",
    "    M_pi = np.zeros((n_states, n_states * n_actions))\n",
    "    M_pi[np.where(np.equal(1, np.kron(S, A)))] = ps.reshape(-1)\n",
    "    return M_pi\n",
    "\n",
    "def pi(M_pi, s, a):\n",
    "    \"\"\"\n",
    "    Let state s be indexed by i and the action a be indexed by j.\n",
    "    Then we have that M[i, i x |A| + j] = pi(a|s)\n",
    "    \"\"\"\n",
    "    return M_pi[s, s*n_actions+a]\n",
    "\n",
    "def normalise(x, axis):\n",
    "    return x/np.sum(x, axis=axis, keepdims=True)\n",
    "\n",
    "def exp_dist(x, lambda_=3.5):  # why 3.5!?\n",
    "    return lambda_*np.exp(-lambda_*x)\n",
    "\n",
    "def uniform_simplex(shape):\n",
    "    # god damn. it's not as simple as I thought to generate uniform distributions on simplexs\n",
    "    # https://cs.stackexchange.com/questions/3227/uniform-sampling-from-a-simplex\n",
    "    # http://www.cs.cmu.edu/~nasmith/papers/smith+tromble.tr04.pdf\n",
    "    return normalise(exp_dist(rnd.random(shape)),axis=1)\n",
    "\n",
    "def generate_rnd_policy(n_states, n_actions):\n",
    "    return generate_Mpi(n_states, n_actions, uniform_simplex((n_states, n_actions)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def bellman_error(f, pi):\n",
    "    d_pi = discounted_state_visitation_distribution(d_0, pi, P)  # the discounted distribution over states\n",
    "    deltas = f(s, pi(s)) - r - f(s, greedy_policy(f))\n",
    "    return np.dot(d_pi, deltas.T)  # the expectation\n",
    "\n",
    "def bellman_error_matrix(F, P, r, t):\n",
    "    n = len(F)\n",
    "    E = np.zeros((n, n))\n",
    "    for i, f in enumerate(F):\n",
    "        for j, g in enumerate(F):\n",
    "            E[i, j] = bellman_error(f, greedy_policy(g))\n",
    "    return E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
