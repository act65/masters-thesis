{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just start with binary testing.\n",
    "\n",
    "There exists a test that returns;\n",
    "- true if you have cancer, \n",
    "    - or a small chance of returning true if you dont have cancer\n",
    "- true if you have cancer, \n",
    "    - or a small chance of returning true if you dont have cancer\n",
    "    \n",
    "    \n",
    "You want to know the truth, for the minimum cost.\n",
    "- True positive: yeah, that's bad.\n",
    "- False negative: yeah that's worse, you dont realies you have X, and can't seek potential treatment.\n",
    "- False positive: not great. You / your doctors think you have cancer, when you dont. You might even be put through a few rounds of chemo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x)/np.sum(np.exp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = np.array([\n",
    "    [0.7, 0.2], #[ TP, FP ]\n",
    "    [0.3, 0.8]  #[ FN, TN ]\n",
    "])\n",
    "\n",
    "def transition_fn(h, s, a):\n",
    "    if a == 1:  # test\n",
    "        s = np.vstack([s, np.random.choice([-1, 1], p=P[:, h])])\n",
    "    elif a == 0:  # dont test\n",
    "        s = np.vstack([s, 0])\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = np.array([\n",
    "    [1.0, 0.5], #[ TP, FP ]\n",
    "    [1.2, 0.0]  #[ FN, TN ]\n",
    "])\n",
    "\n",
    "individial_test_cost = 100\n",
    "\n",
    "def cost_fn(truth, n_tests, guess):\n",
    "    return 1000 * C[guess, truth] + individial_test_cost * n_tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is this actually a MDP?!\n",
    "# dont think so??? actually, maybe it is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Truth: 1, Diagnosis: 1\n"
     ]
    }
   ],
   "source": [
    "truth = 1\n",
    "s = np.empty(shape=(1, ))\n",
    "for _ in range(10):\n",
    "    a = np.random.choice([0, 1])\n",
    "    s = transition_fn(truth, s, a)\n",
    "\n",
    "diagnosis = int(mode(s[s != 0]))\n",
    "\n",
    "c = cost_fn(truth, np.sum(np.abs(s)), diagnosis)\n",
    "print('Truth: {}, Diagnosis: {}'.format(truth, diagnosis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode(x):\n",
    "    (_, idx, counts) = np.unique(x, return_index=True, return_counts=True)\n",
    "    index = idx[np.argmax(counts)]\n",
    "    return x[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# could map distribution of FP / TN / ... through the multiple testing \n",
    "# and aggregation to a distribution over likely diagnoses."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
