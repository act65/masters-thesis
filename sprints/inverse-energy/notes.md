
### Stretch

- Ok, it has limitations. Not able to oscillate (if we only have a single fn). What about an ensemble? How powerful is that? Or local minimisation of an energy fn shared over space/time?
- If we used this model as part of an ensemble, would it learn to model agents, independently capturing their value functions.
- Could extend to adding more structure into the energy function or update? (e.g. scale by hessian)
- computational complexity versus SGD on NN.
- implement on atari.
- problem. for most atari games, a single frame is not enough to fully specify the state, need the velocity as well.
- is it possible to get non-linear behaviour from many locally convex energy fns? (yes?)
- what if we dont get to observe optimal trajectories? only approximately optimal??? humans often dont know the best way...
- model emergent colloidial structures and attempt to learn the (local) energy function they are optimising.
- will NNs work well in this local setting? quite often they will see nothing/be in some local minima!?
- oh... how is this related to equilibrium propagation?!?
- What problems are ensembles of local losses bad at?

### Local loss

$$
\begin{align}
s_{t+1} &\sim \frac{e^{E_G(\textbf s)}}{\sum e^{E_G(s_i)}} \\
E_G &= \sum \dots \sum E_l(s_i) \\
\end{align}
$$

***


Invariance under a contraction operator. Both Bellman and GD, and !?.

$$
\begin{align}
x(t+1) &= T_{GD} x(t) \\
&= x(t) - \eta \frac{\partial E}{\partial x} \\
x_i(t+1) &= T_{BM} x_i(t) \\
&= R + \gamma \mathop{\text{max}}_a \int p(x_i(t), a) \cdot x_{i+1}(t) dx  \\
\end{align}
$$

This just means the steps/iterations will converge to a fixed value.

Hmph.
- But GD isnt always a contraction? GD is only a contraction operator when the loss surface is convex?
- My formulation of the bellman operator doesnt seem right. Is the bellman operator a contraction over $t$ or $i$, or both?

Is it possible to do an eigen analysis of these linear operators?

##### Time series.

Unsupervised learning for time series. How can this be done? It is often done by modelling the time series as being generated by a step function $s_{t+1} = f(s_t)$



## Resources

- [IRL](https://ai.stanford.edu/~ang/papers/icml00-irl.pdf)
- [Apprenticeship via IRL](https://ai.stanford.edu/~ang/papers/icml04-apprentice.pdf)
- [Max entropy IRL](https://www.aaai.org/Papers/AAAI/2008/AAAI08-227.pdf)
- [GANs, IRL, EBMs](https://arxiv.org/abs/1611.03852)
- [DAC for IRL](https://arxiv.org/abs/1809.02925)
- [IOC](https://arxiv.org/abs/1805.08395)
- [Review](https://arxiv.org/abs/1806.06877)
