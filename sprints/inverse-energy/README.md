> 7. Inverse energy learning. Inspired by inverse reinforcement learning [@Ng2000AlgorithmsFI], what if we assume that the observations we make are the results of some optimal action, in this case, of an energy function being minimised.

We are given access to a set of optimal trajectories, $\tau_k = \{x_0, \dots, x_t, \dots, x_T\}$ that are assumed to be generated by taking optimal actions under an energy function. We interpret optimal actions to be steps via gradient descent (rather than the maximisation of the bellman operator).

Let $E$ be the energy function being minimised, and let $x_t$ be our observations (and/or the state) at time $t$.

$$
\begin{align}
x_{t+1} &= f(x_t) \\
x_{t+1} &= x_t - \eta \nabla E(x_t) \\
\end{align}
$$

### 1) Motivate the idea as a solution to an existing problem (see future-inverse.md)

__Claim 1.__ Is it better to have the energy function or the step function?

- It is easy to calculate steps from the energy fn. It only rquires differentiation (which is O(?))
- It is not easy to calculate the energy with only the step function. You would need to integrate.

<font color='red'>TODO</font> want to make this argument more formal! Comptational complexity.

__Claim 2.__ Generalise better.

<font color='red'>TODO</font> want to make this argument more formal! Sample complexity.

__Claim 3.__ A communication problem between teacher and student.

Info required to communicate E is much more that dE!?

<font color='red'>TODO</font> want to make this argument more formal! Communication complexity.

### 2) Demonstrate that the "existing" problem really exists

Why is learning an energy function hard? Is it even hard?

Under-constrained problem. Many possible energy functions could fit the observations. (but many more step functions?)

### 3) Generate alternative solutions and a suitable baseline

Compare:

- vanilla neural network,
- residual neural network,
- IEL,
- ?.

Possible ways to train the learned energy?

- Max likelihood - $\mathop{\text{argmax}}_{\theta} \prod_{i=1}^T p(x_i \mid x_{i-1}: x_0)$
- Squared error - $\mathop{\text{argmin}}_{\theta} \parallel f(x_t) - x_{t+1} \parallel$

### 4) Design the minimal viable experiment to falsify the proposed solution

- Learn a simple 1d energy function using observations of its gradients.
- Learn a n-d energy function from trajectories of gradient descent.
- Grid world experiment?
- partial observations via a projection matrix!?

Want a set of simple trajectories, agent moves in a straight line towards its goal. E should learn to measure the (squared) distance!?w
