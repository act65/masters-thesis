{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using numpy backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorly as tl\n",
    "from tensorly.decomposition import tucker "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why is this hard to think about!?\n",
    "\n",
    "Want to find temporally abstract patterns between observations, actions and rewards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('LunarLander-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def play_episode(player, env, len_episode=100):\n",
    "    obs = env.reset()\n",
    "    trajectory = []\n",
    "    old_obs = obs\n",
    "    done = False\n",
    "    \n",
    "    # need fixed length trajectories\n",
    "    for _ in range(len_episode):\n",
    "        if not done:\n",
    "            a = player(obs)\n",
    "            obs, r, done, info = env.step(a)\n",
    "            \n",
    "        else:  # pad with zeros\n",
    "            a = 0\n",
    "            obs, r, done, info = (np.zeros(8), 0, done, None)\n",
    "            \n",
    "        trajectory.append(np.concatenate([np.array([a]), old_obs, np.array([r])]))\n",
    "        old_obs = obs\n",
    "    return np.vstack(trajectory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total possible trajectories = 1267650600228229401496703205376\n"
     ]
    }
   ],
   "source": [
    "len_episode = 50\n",
    "n_actions = 4\n",
    "n_possible_trajectories = n_actions**len_episode\n",
    "print('Total possible trajectories = {}'.format(n_possible_trajectories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectory = play_episode(lambda *args: env.action_space.sample(), env, len_episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate dataset using rnd policy\n",
    "dataset = np.stack([play_episode(lambda *args: env.action_space.sample(), env, len_episode)\n",
    "                      for _ in range(1000)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 50, 10)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = dataset[:,1:,0]\n",
    "actions = tf.constant(actions, dtype=tf.int32)\n",
    "actions = tf.one_hot(actions, axis=-1, depth=4, off_value=0.0,on_value=1.0)\n",
    "actions = actions.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 49, 4) (1000, 49, 8)\n"
     ]
    }
   ],
   "source": [
    "# should use difference in observations/state?\n",
    "# actions wouldnt necessarily correlate with absolute obs\n",
    "# could have the same trajectory, with zero correlation bc different starting pts!?\n",
    "obs = dataset[:,1:,1:-1] - dataset[:,:-1,1:-1]\n",
    "print(actions.shape, obs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = np.sum(dataset[:,1:,-1], axis=-1)\n",
    "R.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are we trying to do here?\n",
    "# are there any patterns between the trajectory of actions and the observations?!?\n",
    "corr = np.einsum('ijk,ijl->jkl', actions, obs)\n",
    "corr /= dataset.shape[0]  # need to normalise!?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 4, 8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "C, G = tucker(tensor=corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((49, 4, 8), [(49, 49), (4, 4), (8, 8)])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.shape, [g.shape for g in G]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5140264438>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAADcAAAD8CAYAAADT9DwxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAABpVJREFUeJztnVuIVVUYx3//mcamsjJT7OKQhlLYQwYiWi/Rhcwie4hQInoQJEooCsoKgqKHgujyFkM3g8jsQoUYFV2QoLxUdlHLG5VKZVk6GZTofD3sNcczZy5nzzn7zJxv/H5wmL3WWefs7zf7cvbDn7VkZoxWWka6gEYScl4JOa+EnFdCbiAkzZP0g6TtkpYVVVRRqNYnFEmtwFbgSmA3sB5YZGabB/rMhPGtNqWjrdTe9t3YvoMq65H6DOnq3veHmU2sVuNx1QYMwmxgu5ntzGrQCmABMKDclI421r3XUWpfPe3ivoO6u3u3W/qeXO//89JPeQqs57Q8G9hV1t6d+pqGht9QJC2RtEHSht/3HWn07npRz2m5B+goa09Ofb0ws06gE+AUjberzppZeq/lpL7XE62tdZTUm3qO3HpguqSpksYAC4F3iimrGGo+cmZ2WNJS4D2gFXjezDYVVlkB1HNaYmargdUF1VI4o/oJpa4jN1TU0kLLiScN2/5G9ZELOa+EnFdCzish55WQ80rIeSXkvBJyXgk5r4ScV0LOKyHnlZDzSsh5JeS8EnJeqSon6XlJeyV9V9Y3XtIHkralv6c1tszayHPkXgTmVfQtAz40s+nAh6nddFSVM7M1wJ8V3QuA5Wl7OXB9wXUVQq3X3CQz+yVt/wpMKqieQqn7hmJZpnHAXGN59uuQ/Vvv7oZErXK/SToTIP3dO9BAM+s0s1lmNmuM2mvcXW3UKvcOcEvavgV4u5hyiiXPT8ErwGfAeZJ2S1oMPApcKWkbcEVqNx1VE0RmtmiAty4vuJbCObafUDwTcl4JOa+EnFdCzish55WQ80rIeSXkvBJyXgk5r4ScV0LOKyHnlZDzSsh5JeS8EnJeyZNm6JD0saTNkjZJuiP1N324Lc+ROwzcbWYzgDnA7ZJm4CDclifY9ouZfZm2/wa2kM3v1fThtiHNZCNpCnARsJac4TZJS4AlAO0avllsYAg3FEljgTeAO82sq/y9wcJtTZ/9ktRGJvaymb2ZunOH20aKPHdLAc8BW8zsibK3mj7clueauwS4GfhW0sbUdz9ZmG1lCrr9BNzYmBJrJ0+w7VOgn0nxgCYPtx3bTyieCTmvhJxXQs4rIeeVkPNKyHkl5LwScl4JOa+EnFdCzish55WQ80rIeSXkvBJyXjm25SS1S1on6euU/Xoo9U+VtDYtZvlqWqatqchz5P4DLjOzC4GZwDxJc4DHgCfNbBrwF7C4cWXWRp7sl5nZwdRsSy8DLgNeT/1Nmf3KmyBqTRmUvcAHwA5gv5kdTkOabjFLyClnZkfMbCbZuo6zgfPz7sDNpGZmth/4GJgLjJPUE9LpdzHL9JnmDbZJmihpXNo+gWxF3C1kkjekYW6zX2cCy9Nyvy3ASjNbJWkzsELSI8BXZOG3piJP9usbsgBpZf9OsuuvaTm2n1A8E3JeCTmvhJxXQs4rIeeVkPNKyHkl5LwScl4JOa+EnFdCzish55WQ80rIeSXkvBJyUArafCVpVWqPiuxXD3eQRTR68J/9ApA0GbgGeDa1xWjJfgFPAfcA3al9OqMh+yXpWmCvmX1Ryw5GMvuVd/ao6yTNB9qBU4CnSdmvdPQGzX4BnQCntk4YcFXPRpAnb3mfmU02synAQuAjM7sJB9mven7n7gXukrSd7Br0l/0qx8w+AT5J25H9GklCzish55WQ80rIeSXkvBJyXgk5r4ScV0LOKyHnlZDzSsh5JeS8EnJeCTmvhJxXlC1ANkw7k34nW1pqAvBHzo/1N/YcM5tYdX/DKVfaqbTBzGYVPbaSUX1ahlwD6GzQ2F6MyDU3XMRpWSuS5kn6IQVO+6zDKun4FET9UVJXWpC2tFBtxdhLJR2QtDG9HqxagJk15AW0kk1bdy4wBvgamFEx5jbgGbLpt5YBrwInA1v7GXspsGooNTTyyM0GtpvZTjM7BKwgW3i2nAXA8rRe6+Nkyywe5OhCtXXRSLmzgV1l7f4Cp6UxKdp4gGyayZ6FaiuZm+bZfFfSBdUKGFKwbRgQ8AL9LFQLfEn22HUwZT/fAqYP9mWNPHJ7gI6ydn+B09IYSe1pzEtlC9WWMLOunnk2zWw10CZpwqAVNPCGchywE5jK0RvKBRVjbie7oQhYA2wd5PvO4Ojv8mzg5572gJ9plFwqYj7ZnW8H8EDqexi4Lm23A6+RXY8GfA9sTK/5wK3ArWnsUmBT+id9Dlxcbf/xhOKVkPNKyHkl5LwyquX+B7rXOYtMUooUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "out = np.einsum('ijk,li,jm->ij', C, G[0], G[1])\n",
    "# marginalise over g[-1] the observations\n",
    "plt.imshow(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
