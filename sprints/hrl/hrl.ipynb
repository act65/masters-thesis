{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "tfd = tfp.distributions\n",
    "\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_net():\n",
    "    return tf.keras.Sequential([\n",
    "        tf.keras.layers.LSTM(64, activation=tf.nn.selu, return_sequences=True),\n",
    "#         tf.keras.layers.Dense(64, activation=tf.nn.selu),\n",
    "#         tf.keras.layers.Dense(64, activation=tf.nn.selu),\n",
    "        tf.keras.layers.Dense(1),\n",
    "        tf.keras.layers.Flatten()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discount_rewards(rewards, gamma):\n",
    "    rewards = reversed(tf.unstack(rewards))\n",
    "    return tf.stack(list(reversed(list(itertools.accumulate(rewards, lambda x, y: x*gamma+y)))), axis=0)\n",
    "#     return tf.expand_dims(tf.accumulate_n(lambda x, y: x+gamma*y, tf.transpose(rewards)), -1)\n",
    "\n",
    "class Critics():\n",
    "    \"\"\"\n",
    "    Train an ensemble of critics at different time scales.\n",
    "    Same input (extension - could be different inputs...)\n",
    "    Different targets\n",
    "    \"\"\"\n",
    "    # oh shit! this is going to turn into something like GVFs!?!?!? sick!\n",
    "    def __init__(self, n_critics):\n",
    "        self.fns = [build_net() for _ in range(n_critics)]\n",
    "    \n",
    "    def __call__(self, state):\n",
    "        # want to calculate this more efficiently.\n",
    "        # maybe using heirarchical LSTMs? or GVFs/cumulants!?\n",
    "        return tf.add_n([fn(state) for fn in self.fns])\n",
    "    \n",
    "    def get_loss(self, state, r):\n",
    "        vs = [fn(state) for fn in self.fns]\n",
    "        rs = [discount_rewards(r, g) for g in [0.999, 0.99, 0.9]]\n",
    "        return tf.add_n([tf.losses.mean_squared_error(r, v) for r, v in zip(vs, rs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "critics = Critics(3)\n",
    "\n",
    "states = tf.random_normal([5, 20, 3])\n",
    "rs = tf.random_normal([5, 20])\n",
    "v = critics(states)\n",
    "loss = critics.get_loss(states, rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So I should be able to use this in a vanilla A2C framework?\n",
    "# Does it help!?\n",
    "\n",
    "# Ok, but want HRL! How can we choose actions in a heirarchical manner?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discount_rewards(rewards, gamma):\n",
    "    rewards = tf.unstack(rewards)\n",
    "    return tf.stack(list(reversed(list(itertools.accumulate(list(reversed(rewards)), lambda x, y: x+gamma*y)))), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discount_rewards(rewards, gamma):\n",
    "    rewards = tf.unstack(rewards)\n",
    "    return tf.stack(list(reversed(list(itertools.accumulate(list(reversed(rewards)), lambda x, y: x+gamma*y)))), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = tf.reshape(y, [1, 1000, 1])\n",
    "w = tf.exp(tf.reshape(tf.constant(range(10), dtype=tf.float32), [10, 1, 1]))\n",
    "z = tf.nn.conv1d(y, w, 1, \"SAME\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.linspace(0.0,12.0, 1000)\n",
    "y = tf.sin(x*3)+tf.sin(x*4+0.2) + tf.sin(x*5+0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, z[0, :, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concrete(x):\n",
    "    n = tf.random_uniform(minval=0, maxval=1, dtype=tf.float32, shape=tf.shape(x)[0])\n",
    "    g = -tf.log(-tf.log(n))\n",
    "    return tf.argmax(tf.log(x) + g, axis=-1)\n",
    "\n",
    "class ActorCritic():\n",
    "    def __init__(self, n_actions):\n",
    "        self.nn = tf.keras.Sequential([\n",
    "            tf.keras.layers.Dense(64, activation=tf.nn.selu),\n",
    "            tf.keras.layers.Dense(n_actions+1),\n",
    "        ])\n",
    "        \n",
    "        \n",
    "    def __call__(self, x):\n",
    "        z = self.nn(x)\n",
    "        return z[..., :-1], z[..., -1:]\n",
    "    \n",
    "    def loss(self, x, a, r):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "learners = [ActorCritic(4) for _ in range(4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tf.random_normal([1, 8])\n",
    "logits, vs = [tf.add_n(arr) for arr in zip(*[l(s) for l in learners])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=717, shape=(1, 4), dtype=float32, numpy=\n",
       "array([[ 0.46686375, -0.72043324,  2.715553  ,  1.7438973 ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what am I trying to build here.\n",
    "# what bias am I trying to encode?\n",
    "# use low freq when possible?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
