\chapter{Introduction}\label{C:intro}

% RL is inefficient
Reinforcement learning has an efficiency problem: AlphaGo \cite{Silver2016a} (the Go
playing AI that beat world champion Lee Sedol) played 1.28 million games, with
extra supervision from another 29.4 million positions, using 50 GPUs.
OpenAI Five \cite{OpenAI2018} (the Dota 2 playing AI that beat OG, the winners of TI8/9) was
trained over 10 months, collecting 900 years of experience per day, using
128,000 CPUs and 256 GPUs. Is RL fundamentally expensive, or can we do better?

% Existing theory tells us ...
Bounds on sample and computational complexity tell us that !??!

% What strategies are there to improve the efficiency of RL?
