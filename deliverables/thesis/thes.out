\BOOKMARK [0][-]{chapter.1}{Introduction}{}% 1
\BOOKMARK [1][-]{section.1.1}{Reinforcement learning}{chapter.1}% 2
\BOOKMARK [1][-]{section.1.2}{Related work}{chapter.1}% 3
\BOOKMARK [2][-]{subsection.1.2.1}{Model-based RL}{section.1.2}% 4
\BOOKMARK [2][-]{subsection.1.2.2}{Representation learning and abstraction}{section.1.2}% 5
\BOOKMARK [0][-]{chapter.2}{MDPs}{}% 6
\BOOKMARK [1][-]{section.2.1}{The value function polytope}{chapter.2}% 7
\BOOKMARK [2][-]{subsection.2.1.1}{Distribution of policies}{section.2.1}% 8
\BOOKMARK [2][-]{subsection.2.1.2}{Discounting}{section.2.1}% 9
\BOOKMARK [1][-]{section.2.2}{Search spaces}{chapter.2}% 10
\BOOKMARK [2][-]{subsection.2.2.1}{Dynamics and complexity}{section.2.2}% 11
\BOOKMARK [2][-]{subsection.2.2.2}{Search spaces and gradient descent}{section.2.2}% 12
\BOOKMARK [0][-]{chapter.3}{Abstraction}{}% 13
\BOOKMARK [1][-]{subsection.3.0.1}{Solveable representations}{chapter.3}% 14
\BOOKMARK [2][-]{subsection.3.0.2}{Other properties}{subsection.3.0.1}% 15
\BOOKMARK [0][-]{chapter.4}{Conclusions}{}% 16
