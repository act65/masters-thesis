\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}% 
\contentsline {section}{\numberline {1.1}Timeline}{1}{section.1.1}% 
\contentsline {section}{\numberline {1.2}Contributions}{2}{section.1.2}% 
\contentsline {chapter}{\numberline {2}Markov Decision Problems}{5}{chapter.2}% 
\contentsline {section}{\numberline {2.1}Sequential decision problems}{7}{section.2.1}% 
\contentsline {section}{\numberline {2.2}Solving a MDP}{8}{section.2.2}% 
\contentsline {subsection}{\numberline {2.2.1}The Bellman Equations}{9}{subsection.2.2.1}% 
\contentsline {subsection}{\numberline {2.2.2}Complexity}{9}{subsection.2.2.2}% 
\contentsline {section}{\numberline {2.3}A tabular representation of MDPs}{9}{section.2.3}% 
\contentsline {section}{\numberline {2.4}The value function polytope}{12}{section.2.4}% 
\contentsline {subsubsection}{Geometry of the polytope}{14}{section*.23}% 
\contentsline {subsubsection}{Dynamics on the polytope}{14}{section*.24}% 
\contentsline {section}{\numberline {2.5}Search spaces for MDPs}{15}{section.2.5}% 
\contentsline {subsection}{\numberline {2.5.1}Policy search}{16}{subsection.2.5.1}% 
\contentsline {subsubsection}{Policy iteration}{16}{section*.25}% 
\contentsline {subsubsection}{Policy gradients}{18}{section*.26}% 
\contentsline {subsection}{\numberline {2.5.2}Value search}{19}{subsection.2.5.2}% 
\contentsline {chapter}{\numberline {3}Abstraction}{23}{chapter.3}% 
\contentsline {section}{\numberline {3.1}Abstractions for RL}{24}{section.3.1}% 
\contentsline {subsection}{\numberline {3.1.1}Classes of abstraction for RL}{25}{subsection.3.1.1}% 
\contentsline {subsubsection}{Examples}{26}{section*.27}% 
\contentsline {paragraph}{State abstraction}{26}{section*.28}% 
\contentsline {paragraph}{Action abstraction}{26}{section*.29}% 
\contentsline {paragraph}{State-action abstraction}{27}{section*.30}% 
\contentsline {paragraph}{Temporal abstraction}{28}{section*.31}% 
\contentsline {subsection}{\numberline {3.1.2}Discovery}{29}{subsection.3.1.2}% 
\contentsline {subsection}{\numberline {3.1.3}Evaluating abstractions}{31}{subsection.3.1.3}% 
\contentsline {subsubsection}{Coarse abstractions}{32}{section*.32}% 
\contentsline {subsubsection}{Near optimal abstractions}{32}{section*.33}% 
\contentsline {subsubsection}{Efficiently solvable abstractions}{33}{section*.34}% 
\contentsline {paragraph}{Efficient exploration}{33}{section*.35}% 
\contentsline {paragraph}{Efficient control}{34}{section*.36}% 
\contentsline {paragraph}{Efficient inference}{34}{section*.41}% 
\contentsline {subsubsection}{Complexity of finding an abstraction}{35}{section*.42}% 
\contentsline {paragraph}{Single task case}{35}{section*.43}% 
\contentsline {paragraph}{Transfer case}{36}{section*.44}% 
\contentsline {subsection}{\numberline {3.1.4}Related work: Representation learning for RL}{36}{subsection.3.1.4}% 
\contentsline {section}{\numberline {3.2}Solvable representations}{38}{section.3.2}% 
\contentsline {subsection}{\numberline {3.2.1}Linear Markov decision problems (LMDPs)}{38}{subsection.3.2.1}% 
\contentsline {subsubsection}{What do we mean by a linear MDP?}{38}{section*.45}% 
\contentsline {subsubsection}{Constructing a linear MDP}{39}{section*.46}% 
\contentsline {subsubsection}{\color {red}The unconstrained dynamics and state rewards}{41}{section*.53}% 
\contentsline {subsubsection}{The optimal policy}{41}{section*.54}% 
\contentsline {subsubsection}{Solving for the optimal value}{41}{section*.55}% 
\contentsline {subsection}{\numberline {3.2.2}Solving a MDP}{42}{subsection.3.2.2}% 
\contentsline {subsection}{\numberline {3.2.3}Decoding the optimal LMDP policy}{43}{subsection.3.2.3}% 
\contentsline {subsubsection}{Optimality of solutions via LMDPs}{45}{section*.64}% 
\contentsline {subsection}{\numberline {3.2.4}Discussion}{48}{subsection.3.2.4}% 
\contentsline {subsubsection}{Validation}{48}{section*.65}% 
\contentsline {subsubsection}{Linearity in MDPs}{50}{section*.70}% 
\contentsline {section}{\numberline {3.3}Symmetric abstractions}{51}{section.3.3}% 
\contentsline {subsubsection}{Definition}{51}{section*.71}% 
\contentsline {subsection}{\numberline {3.3.1}Symmetries for RL}{52}{subsection.3.3.1}% 
\contentsline {subsection}{\numberline {3.3.2}Exploitation}{53}{subsection.3.3.2}% 
\contentsline {subsubsection}{Exploiting symmetry for efficient control}{53}{section*.72}% 
\contentsline {subsubsection}{Exploiting symmetry for efficient inference}{53}{section*.73}% 
\contentsline {subsubsection}{Exploiting symmetry for efficient exploration}{53}{section*.74}% 
\contentsline {subsection}{\numberline {3.3.3}Discovery}{54}{subsection.3.3.3}% 
\contentsline {subsubsection}{Inferring symmetries from experience}{54}{section*.75}% 
\contentsline {subsubsection}{Invariants}{55}{section*.76}% 
\contentsline {subsection}{\numberline {3.3.4}Inductive bias towards seeing symmetry}{55}{subsection.3.3.4}% 
\contentsline {subsubsection}{Langevin dynamics}{55}{section*.77}% 
\contentsline {subsubsection}{Thompson sampling}{56}{section*.78}% 
\contentsline {chapter}{\numberline {4}Experiments}{59}{chapter.4}% 
\contentsline {section}{\numberline {4.1}Interfaces}{59}{section.4.1}% 
\contentsline {section}{\numberline {4.2}n-dimensional Cart pole}{59}{section.4.2}% 
\contentsline {subsection}{\numberline {4.2.1}How is this problem symmetric?}{59}{subsection.4.2.1}% 
\contentsline {subsection}{\numberline {4.2.2}How might a learner exploit this knowledge to learn more efficiently?}{60}{subsection.4.2.2}% 
\contentsline {subsection}{\numberline {4.2.3}Experiments}{60}{subsection.4.2.3}% 
\contentsline {chapter}{\numberline {5}Conclusions}{65}{chapter.5}% 
\contentsline {chapter}{\numberline {A}MDPs}{77}{appendix.A}% 
\contentsline {section}{\numberline {A.1}MDP examples}{77}{section.A.1}% 
\contentsline {paragraph}{Bus engine replacement}{77}{section*.80}% 
\contentsline {paragraph}{The ALOHA protocol}{77}{section*.81}% 
\contentsline {paragraph}{Mate desertion in Cooper's Hawks}{78}{section*.82}% 
\contentsline {paragraph}{But who's counting?}{78}{section*.83}% 
\contentsline {paragraph}{Diagnosing catnip immunity}{79}{section*.84}% 
\contentsline {paragraph}{Ad targeting}{79}{section*.85}% 
\contentsline {paragraph}{Youtube recommendation}{80}{section*.86}% 
\contentsline {paragraph}{Salamon harvesting}{80}{section*.87}% 
\contentsline {paragraph}{Fire engine allocation}{80}{section*.88}% 
\contentsline {section}{\numberline {A.2}Tabular MDPs}{81}{section.A.2}% 
\contentsline {section}{\numberline {A.3}Policies in high dimensions}{82}{section.A.3}% 
\contentsline {section}{\numberline {A.4}Other properties of the polytope}{83}{section.A.4}% 
\contentsline {subsection}{\numberline {A.4.1}Distribution of policies}{83}{subsection.A.4.1}% 
\contentsline {subsection}{\numberline {A.4.2}Discounting}{85}{subsection.A.4.2}% 
\contentsline {subsection}{\numberline {A.4.3}Derivation of derivative}{85}{subsection.A.4.3}% 
\contentsline {section}{\numberline {A.5}Model search}{88}{section.A.5}% 
\contentsline {subsection}{\numberline {A.5.1}Compressed sensing}{88}{subsection.A.5.1}% 
\contentsline {subsection}{\numberline {A.5.2}Off policy value estimation}{90}{subsection.A.5.2}% 
\contentsline {subsection}{\numberline {A.5.3}Failure of next step prediction supervision}{90}{subsection.A.5.3}% 
\contentsline {section}{\numberline {A.6}Visualising higher dimensional MDPs}{91}{section.A.6}% 
\contentsline {section}{\numberline {A.7}Deep policy gradients}{92}{section.A.7}% 
\contentsline {section}{\numberline {A.8}Topology and dynamics}{93}{section.A.8}% 
\contentsline {subsection}{\numberline {A.8.1}Acceleration and parameterisation}{94}{subsection.A.8.1}% 
\contentsline {section}{\numberline {A.9}Conclusion}{95}{section.A.9}% 
\contentsline {chapter}{\numberline {B}Abstraction}{99}{appendix.B}% 
\contentsline {section}{\numberline {B.1}Similarity}{99}{section.B.1}% 
\contentsline {subsection}{\numberline {B.1.1}Pairing abstractions with similarity measures}{99}{subsection.B.1.1}% 
\contentsline {section}{\numberline {B.2}LMDPs}{100}{section.B.2}% 
\contentsline {subsection}{\numberline {B.2.1}Derivation}{100}{subsection.B.2.1}% 
\contentsline {subsubsection}{LMDP solutions}{100}{section*.111}% 
\contentsline {subsubsection}{MDP Linearisation}{102}{section*.134}% 
\contentsline {section}{\numberline {B.3}Symmetry}{104}{section.B.3}% 
\contentsline {subsection}{\numberline {B.3.1}Efficient inference using symmetries}{104}{subsection.B.3.1}% 
\contentsline {paragraph}{Output coupling}{104}{section*.161}% 
\contentsline {paragraph}{Gradient coupling}{104}{section*.162}% 
\contentsline {paragraph}{Data augmentation}{104}{section*.163}% 
\contentsline {paragraph}{Architecture}{104}{section*.164}% 
\contentsline {subsection}{\numberline {B.3.2}Cart pole}{105}{subsection.B.3.2}% 
\contentsline {subsubsection}{Mirror symmetry}{105}{section*.165}% 
\contentsline {subsubsection}{Translational symmetry}{106}{section*.172}% 
\contentsline {subsubsection}{Future translational symmetry}{107}{section*.179}% 
\contentsline {subsubsection}{Temporal symmetry}{108}{section*.180}% 
\contentsline {subsection}{\numberline {B.3.3}Pong}{109}{subsection.B.3.3}% 
\contentsline {subsubsection}{Mirror symmetry (vertical)}{109}{section*.181}% 
\contentsline {paragraph}{Mirror symmetry (horizontal)}{110}{figure.B.6}% 
\contentsline {paragraph}{Translational symmetry}{111}{figure.B.7}% 
\contentsline {paragraph}{Temporal symmetries}{112}{figure.B.8}% 
