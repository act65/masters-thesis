\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}% 
\contentsline {section}{\numberline {1.1}Reinforcement learning}{1}{section.1.1}% 
\contentsline {subsection}{\numberline {1.1.1}Understanding Theoretical Reinforcement learning}{2}{subsection.1.1.1}% 
\contentsline {subsection}{\numberline {1.1.2}Understanding Markov decision problems}{3}{subsection.1.1.2}% 
\contentsline {subsection}{\numberline {1.1.3}Abstraction}{3}{subsection.1.1.3}% 
\contentsline {subsubsection}{Algorithms}{3}{section*.3}% 
\contentsline {chapter}{\numberline {2}MDPs}{5}{chapter.2}% 
\contentsline {subsection}{\numberline {2.0.1}Sequential decision problems}{5}{subsection.2.0.1}% 
\contentsline {subsection}{\numberline {2.0.2}MDPs}{5}{subsection.2.0.2}% 
\contentsline {subsubsection}{The Markov property}{6}{section*.4}% 
\contentsline {subsubsection}{Optimality}{6}{section*.5}% 
\contentsline {subsubsection}{How do MDPs relate to RL?}{7}{section*.6}% 
\contentsline {subsubsection}{A tabular representation of MDPs}{7}{section*.7}% 
\contentsline {subsubsection}{Learning the (tabular) abstraction}{8}{section*.10}% 
\contentsline {section}{\numberline {2.1}The value function polytope}{8}{section.2.1}% 
\contentsline {subsection}{\numberline {2.1.1}Distribution of policies}{9}{subsection.2.1.1}% 
\contentsline {paragraph}{An MDPs Entropy}{11}{section*.17}% 
\contentsline {subsection}{\numberline {2.1.2}Discounting}{13}{subsection.2.1.2}% 
\contentsline {section}{\numberline {2.2}Search spaces}{14}{section.2.2}% 
\contentsline {subsection}{\numberline {2.2.1}Dynamics and complexity}{14}{subsection.2.2.1}% 
\contentsline {subsection}{\numberline {2.2.2}Search spaces and gradient descent}{16}{subsection.2.2.2}% 
\contentsline {paragraph}{Value iteration}{17}{section*.20}% 
\contentsline {paragraph}{Policy iteration}{17}{section*.21}% 
\contentsline {paragraph}{Model iteration}{17}{section*.22}% 
\contentsline {subsubsection}{Topology and dynamics}{20}{section*.23}% 
\contentsline {subsubsection}{Accleration and parameterisation}{20}{section*.24}% 
\contentsline {subsubsection}{Continuous flow and its discretisation}{23}{section*.25}% 
\contentsline {chapter}{\numberline {3}Abstraction}{25}{chapter.3}% 
\contentsline {section}{\numberline {3.1}Near optimal abstractions}{26}{section.3.1}% 
\contentsline {paragraph}{Other types of abstraction}{28}{section*.26}% 
\contentsline {subsubsection}{Motivating example for state and action abstraction: ???}{29}{section*.35}% 
\contentsline {subsubsection}{Motivating example for state-action abstraction: Symmetric maze}{29}{section*.36}% 
\contentsline {subsubsection}{Related work}{29}{section*.37}% 
\contentsline {subsection}{\numberline {3.1.1}Discussion}{29}{subsection.3.1.1}% 
\contentsline {section}{\numberline {3.2}Solvable representations}{32}{section.3.2}% 
\contentsline {subsubsection}{Why linearity?}{32}{section*.38}% 
\contentsline {subsubsection}{A closer look at LMDPs}{32}{section*.39}% 
\contentsline {paragraph}{LMDPs; more formally}{34}{figure.3.2}% 
\contentsline {paragraph}{A relaxed MDP}{34}{figure.3.3}% 
\contentsline {subparagraph}{Unconstrained dynamics and state rewards}{36}{section*.52}% 
\contentsline {paragraph}{Decoding}{38}{figure.3.4}% 
\contentsline {paragraph}{Optimality of solutions via LMDPs}{38}{section*.54}% 
\contentsline {paragraph}{Option decoding}{40}{section*.71}% 
\contentsline {subsubsection}{The complexity of solutions via LMDPs}{40}{section*.72}% 
\contentsline {subsubsection}{Scaling to more complex problems}{41}{section*.73}% 
\contentsline {paragraph}{Incremental implementation}{41}{section*.74}% 
\contentsline {subparagraph}{Model based}{41}{section*.75}% 
\contentsline {subsubsection}{Distributions over states}{42}{section*.76}% 
\contentsline {subsection}{\numberline {3.2.1}Other properties}{42}{subsection.3.2.1}% 
\contentsline {section}{\numberline {3.3}Symmetry}{44}{section.3.3}% 
\contentsline {subsection}{\numberline {3.3.1}n-dimensional Cart pole}{44}{subsection.3.3.1}% 
\contentsline {section}{\numberline {3.4}Action abstractions}{46}{section.3.4}% 
\contentsline {chapter}{\numberline {4}Conclusions}{47}{chapter.4}% 
\contentsline {chapter}{\numberline {A}Related work}{51}{appendix.A}% 
\contentsline {section}{\numberline {A.1}Academic literature}{51}{section.A.1}% 
\contentsline {subsection}{\numberline {A.1.1}HRL}{51}{subsection.A.1.1}% 
\contentsline {subsection}{\numberline {A.1.2}Dynamic programming}{53}{subsection.A.1.2}% 
\contentsline {subsection}{\numberline {A.1.3}Model-based RL}{53}{subsection.A.1.3}% 
\contentsline {subsection}{\numberline {A.1.4}Representation learning and abstraction}{54}{subsection.A.1.4}% 
\contentsline {subsection}{\numberline {A.1.5}Heirarchical reinforcement learning}{54}{subsection.A.1.5}% 
