\contentsline {chapter}{\numberline {1}Introduction}{1}{chapter.1}% 
\contentsline {section}{\numberline {1.1}Reinforcement learning}{1}{section.1.1}% 
\contentsline {subsubsection}{Understanding Theoretical Reinforcement learning}{2}{section*.3}% 
\contentsline {subsubsection}{Understanding Markov decision problems}{3}{section*.4}% 
\contentsline {subsubsection}{Abstraction}{3}{section*.5}% 
\contentsline {subsubsection}{Algorithms}{3}{section*.6}% 
\contentsline {section}{\numberline {1.2}Related work}{3}{section.1.2}% 
\contentsline {paragraph}{MDPs}{3}{section*.7}% 
\contentsline {subparagraph}{HRL}{4}{section*.8}% 
\contentsline {paragraph}{Dynamic programming}{5}{section*.9}% 
\contentsline {subsection}{\numberline {1.2.1}Model-based RL}{5}{subsection.1.2.1}% 
\contentsline {subsection}{\numberline {1.2.2}Representation learning and abstraction}{6}{subsection.1.2.2}% 
\contentsline {chapter}{\numberline {2}MDPs}{7}{chapter.2}% 
\contentsline {section}{\numberline {2.1}The value function polytope}{7}{section.2.1}% 
\contentsline {subsection}{\numberline {2.1.1}Distribution of policies}{8}{subsection.2.1.1}% 
\contentsline {paragraph}{An MDPs Entropy}{9}{section*.12}% 
\contentsline {subsection}{\numberline {2.1.2}Discounting}{11}{subsection.2.1.2}% 
\contentsline {section}{\numberline {2.2}Search spaces}{11}{section.2.2}% 
\contentsline {subsection}{\numberline {2.2.1}Dynamics and complexity}{11}{subsection.2.2.1}% 
\contentsline {subsection}{\numberline {2.2.2}Search spaces and gradient descent}{14}{subsection.2.2.2}% 
\contentsline {paragraph}{Value iteration}{15}{section*.15}% 
\contentsline {paragraph}{Policy iteration}{15}{section*.16}% 
\contentsline {paragraph}{Model iteration}{15}{section*.17}% 
\contentsline {subsubsection}{Topology and dynamics}{16}{section*.18}% 
\contentsline {subsubsection}{Accleration and parameterisation}{17}{section*.19}% 
\contentsline {subsubsection}{Continuous flow and its discretisation}{19}{section*.20}% 
\contentsline {chapter}{\numberline {3}Abstraction}{21}{chapter.3}% 
\contentsline {subsection}{\numberline {3.0.1}Solveable representations}{21}{subsection.3.0.1}% 
\contentsline {subsubsection}{Why linearity?}{21}{section*.21}% 
\contentsline {subsubsection}{A closer look at LMDPs}{22}{section*.22}% 
\contentsline {paragraph}{LMDPs; more formally}{22}{figure.3.1}% 
\contentsline {paragraph}{A relaxed MDP}{25}{figure.3.2}% 
\contentsline {subparagraph}{Unconstrained dynamics and state rewards}{26}{section*.35}% 
\contentsline {paragraph}{Decoding}{26}{figure.3.3}% 
\contentsline {paragraph}{Optimality of solutions via LMDPs}{28}{section*.37}% 
\contentsline {paragraph}{Option decoding}{29}{section*.54}% 
\contentsline {subsubsection}{The complexity of solutions via LMDPs}{29}{section*.55}% 
\contentsline {subsubsection}{Scaling to more complex problems}{30}{section*.56}% 
\contentsline {paragraph}{Incremental implementation}{30}{section*.57}% 
\contentsline {subparagraph}{Model based}{31}{section*.58}% 
\contentsline {subsubsection}{Distributions over states}{31}{section*.59}% 
\contentsline {subsection}{\numberline {3.0.2}Other properties}{32}{subsection.3.0.2}% 
\contentsline {chapter}{\numberline {4}Conclusions}{33}{chapter.4}% 
