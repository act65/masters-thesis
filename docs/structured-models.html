<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>structured models</title>
  <style type="text/css">
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <link rel="stylesheet" href="../style.css">
  <script src="../docs/mathjax.js" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <script type="text/x-mathjax-config">
    // MathJax.Hub.Config({ TeX: { equationNumbers: {autoNumber: "all"} } });
    MathJax.Hub.Config({
      extensions: ["tex2jax.js"],
      jax: ["input/TeX", "output/HTML-CSS"],
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
      },
      "HTML-CSS": { fonts: ["TeX"] }
    });
  </script>
</head>
<body>
<header>
<h1 class="title">structured models</h1>
</header>
<h1 id="structured-models">Structured models</h1>
<p>Why is it hard to learn a good model?</p>
<ul>
<li>uncertainty</li>
<li>partial observations</li>
<li>complexity</li>
<li>low frequency events (how is this related to complexity?)</li>
</ul>
<h2 id="compression">Compression</h2>
<p>But we really want the model to approximate the true internal structure of the environment, not just an arbitrary structured function approimation. Want to recover the truth. Do science, extract relationships, reduce into minimal parts.</p>
<p>Therefore we need a measure of complexity that we can minimise.</p>
<h2 id="partial-observations">Partial observations</h2>
<p>How can we construct global models from local observations?</p>
<p><strong>Conjecture:</strong> To efficiently build a global model is it necessary for the agent to estimate its position in its environment.</p>
<p>But where does the ground truth signal come from!?</p>
<h2 id="modelling-uncertainty">Modelling uncertainty</h2>
<p>Distributions over plausible states? MCMC estimation versus using flows?!?</p>
<h2 id="graph-neural-networks">Graph neural networks</h2>
<p>!?!? How to contruct a structured representation from partial observations!?!!</p>
<h2 id="approximate-gradient-dynamics">Approximate gradient dynamics</h2>
<p>Want to recover the dynamics of a system, and its state. How can these be disentangled??</p>
<h3 id="approximate-gradient-dynamics-1">Approximate gradient dynamics</h3>
<p>How can we efficiently approimate a dynamical system?</p>
<p>We have observations <span class="math inline">\(\{x(t_0),x(t_1), \dots , x(t), x(t_{+1}) \}\)</span> and know that they are produced via a dynamical system.</p>
<p><span class="math display">\[
\begin{align*}
\frac{dx}{dt} &amp;= f(x) \\
\end{align*}
\]</span></p>
<p><strong>NOTE</strong> Would make it easy(er) to design an exploitable model!? Controller simply inputs stepsize.</p>
<h3 id="inverse-gradient-dynamics">Inverse gradient dynamics</h3>
<p>(relationship to IRL?)</p>
<p>Assume that the dynamcs of a system are the result of an energy being minimised.</p>
<p><span class="math display">\[
\begin{align*}
x_{t+1} &amp;= x_t - \eta\nabla E(x_t) \tag{the true dynamics}\\
f(x_t) &amp;= x_t - \nabla \hat E_{\theta}(x_t) \tag{approximate the energy fn}\\
L &amp;= \mathop{\mathbb E}_{x_{t+1}, x_t\sim D} \big[ d(x_{t+1}, f(x_t)) \big] \tag{loss fn for approximation}\\
\end{align*}
\]</span></p>
<ul>
<li>(how does this constrain the possible types of dynamics?)</li>
<li>if we use an ensemble of approximators, how will the dynamics be decomposed? will we naturally see environment disentangled from agents?</li>
</ul>
<h3 id="differentiable-ode-solvers-for-simulation">Differentiable ODE solvers for simulation</h3>
<p>â€¦</p>
<h2 id="causal-inference">Causal inference</h2>
<ul>
<li>How is RL like the interventional level of the causal heirarchy?</li>
<li>How is model-based RL like the counter-factual level of the causal heirarchy?</li>
<li>How can we automate reductionism?</li>
<li>?</li>
</ul>
<h2 id="resources">Resources</h2>
<ul>
<li><a href=""></a></li>
<li><a href=""></a></li>
</ul>
</body>
</html>
